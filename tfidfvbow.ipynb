{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tfidfvbow.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R90q9co84Otw",
        "colab_type": "text"
      },
      "source": [
        "# NLP Analysis: Bag of Words vs TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPLhls-LsPww",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZmdTz1KIRfx",
        "colab_type": "code",
        "outputId": "a5141178-6e0d-4502-e927-7c41fa0272c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "import math\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import warnings\n",
        "\n",
        "from IPython.display import display\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import statsmodels.formula.api as smf\n",
        "from matplotlib.mlab import PCA as mlabPCA\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn import linear_model\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn import neighbors\n",
        "from sklearn.utils import resample\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import ensemble\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.decomposition import KernelPCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from datetime import datetime\n",
        "from dateutil.parser import parse\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.corpus import gutenberg, stopwords\n",
        "\n",
        "\n",
        "\n",
        "# Display preferences.\n",
        "%matplotlib inline\n",
        "pd.options.display.float_format = '{:.3f}'.format\n",
        "\n",
        "# Suppress annoying harmless error.\n",
        "warnings.filterwarnings(\n",
        "    action=\"ignore\",\n",
        "    module=\"sklearn\"  \n",
        "    )\n",
        "\n",
        "# Set Plot Style\n",
        "sns.set_style('white')\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "!python -m spacy download en\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n",
            "Requirement already satisfied: en_core_web_sm==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz#egg=en_core_web_sm==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n",
            "CPU times: user 1.12 s, sys: 232 ms, total: 1.36 s\n",
            "Wall time: 3.86 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITLX6eFVLTRj",
        "colab_type": "code",
        "outputId": "39e64eb4-79c4-414c-83de-28d58e60d748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "# Grab and process the raw data.\n",
        "print(gutenberg.fileids())\n",
        "\n",
        "brown = gutenberg.raw('chesterton-brown.txt')\n",
        "stories = gutenberg.raw('bryant-stories.txt')\n",
        "parents = gutenberg.raw('edgeworth-parents.txt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n",
            "CPU times: user 5.35 ms, sys: 1.87 ms, total: 7.22 ms\n",
            "Wall time: 11.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-nkFkK8fGHt",
        "colab_type": "code",
        "outputId": "9bb235c7-5d64-4d6e-c749-91054465ea4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Define Reusable Functions\n",
        "\n",
        "## Text Cleaning Function\n",
        "def text_cleaner(text):\n",
        "    # Visual inspection identifies a form of punctuation spaCy does not\n",
        "    # recognize: the double dash '--'.  Better get rid of it now!\n",
        "    text = re.sub(r'--',' ',text)\n",
        "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "  \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
            "Wall time: 9.78 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaBEftrqL_0r",
        "colab_type": "code",
        "outputId": "9e391c41-0e59-4c5e-cdff-f704bd60af72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Clean text data and reduce to same number of characters\n",
        "brown_1 = text_cleaner(brown[:int(len(stories)/10)])\n",
        "brown_2 = text_cleaner(brown[int(len(stories)/10):2*int(len(stories)/10)])\n",
        "brown_3 = text_cleaner(brown[2*int(len(stories)/10):3*int(len(stories)/10)])\n",
        "brown_4 = text_cleaner(brown[3*int(len(stories)/10):4*int(len(stories)/10)])\n",
        "parents_1 = text_cleaner(parents[:int(len(stories)/10)])\n",
        "parents_2 = text_cleaner(parents[int(len(stories)/10):2*int(len(stories)/10)])\n",
        "parents_3 = text_cleaner(parents[2*int(len(stories)/10):3*int(len(stories)/10)])\n",
        "parents_4 = text_cleaner(parents[3*int(len(stories)/10):4*int(len(stories)/10)])\n",
        "stories_1 = text_cleaner(stories[:int(len(stories)/10)])\n",
        "stories_2 = text_cleaner(stories[int(len(stories)/10):2*int(len(stories)/10)])\n",
        "stories_3 = text_cleaner(stories[2*int(len(stories)/10):3*int(len(stories)/10)])\n",
        "stories_4 = text_cleaner(stories[3*int(len(stories)/10):4*int(len(stories)/10)])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5.12 ms, sys: 0 ns, total: 5.12 ms\n",
            "Wall time: 5.08 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e8FMqhNNIqD",
        "colab_type": "code",
        "outputId": "f3ae14d9-3080-4d88-d411-47ba38cc5602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Parse the cleaned novels\n",
        "nlp = spacy.load('en')\n",
        "brown_1_doc = nlp(brown_1)\n",
        "brown_2_doc = nlp(brown_2)\n",
        "brown_3_doc = nlp(brown_3)\n",
        "brown_4_doc = nlp(brown_4)\n",
        "parents_1_doc = nlp(parents_1)\n",
        "parents_2_doc = nlp(parents_2)\n",
        "parents_3_doc = nlp(parents_3)\n",
        "parents_4_doc = nlp(parents_4)\n",
        "stories_1_doc = nlp(stories_1)\n",
        "stories_2_doc = nlp(stories_2)\n",
        "stories_3_doc = nlp(stories_3)\n",
        "stories_4_doc = nlp(stories_4)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 10.2 s, sys: 345 ms, total: 10.6 s\n",
            "Wall time: 10.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLkANeVANWxV",
        "colab_type": "code",
        "outputId": "7d945a55-03ea-47e9-fbc8-838274319810",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Group into sentences\n",
        "brown_1_sents = [[sent, \"chesterton\"] for sent in brown_1_doc.sents]\n",
        "brown_2_sents = [[sent, \"chesterton\"] for sent in brown_2_doc.sents]\n",
        "brown_3_sents = [[sent, \"chesterton\"] for sent in brown_3_doc.sents]\n",
        "brown_4_sents = [[sent, \"chesterton\"] for sent in brown_4_doc.sents]\n",
        "parents_1_sents = [[sent, \"edgeworth\"] for sent in parents_1_doc.sents]\n",
        "parents_2_sents = [[sent, \"edgeworth\"] for sent in parents_2_doc.sents]\n",
        "parents_3_sents = [[sent, \"edgeworth\"] for sent in parents_3_doc.sents]\n",
        "parents_4_sents = [[sent, \"edgeworth\"] for sent in parents_4_doc.sents]\n",
        "stories_1_sents = [[sent, \"bryant\"] for sent in stories_1_doc.sents]\n",
        "stories_2_sents = [[sent, \"bryant\"] for sent in stories_2_doc.sents]\n",
        "stories_3_sents = [[sent, \"bryant\"] for sent in stories_3_doc.sents]\n",
        "stories_4_sents = [[sent, \"bryant\"] for sent in stories_4_doc.sents]\n",
        " "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.71 ms, sys: 1.98 ms, total: 9.7 ms\n",
            "Wall time: 9.84 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcPHjj7J8Df1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b01cd68d-1369-4afa-8497-da45681a2b77"
      },
      "source": [
        "%%time\n",
        "\n",
        "## Process Text into Sentence Pair Groups\n",
        "\n",
        "brown_all_sents = pd.DataFrame(\n",
        "    brown_1_sents+\n",
        "    brown_2_sents+\n",
        "    brown_3_sents+\n",
        "    brown_4_sents)\n",
        "\n",
        "parents_all_sents = pd.DataFrame(\n",
        "    parents_1_sents+\n",
        "    parents_2_sents+\n",
        "    parents_3_sents+\n",
        "    parents_4_sents)\n",
        "\n",
        "stories_all_sents = pd.DataFrame(\n",
        "    stories_1_sents+\n",
        "    stories_2_sents+\n",
        "    stories_3_sents+\n",
        "    stories_4_sents)\n",
        "\n",
        "\n",
        "\n",
        "brown_all_sents = brown_all_sents.applymap(str)\n",
        "brown_all_sents[0] = brown_all_sents[0].apply(lambda x: x + ' ')\n",
        "brown_all_sents['grp'] = brown_all_sents.index // 2\n",
        "brown_all_sents = brown_all_sents.groupby('grp').sum()\n",
        "brown_all_sents[1] = 'chesterton'\n",
        "\n",
        "parents_all_sents = parents_all_sents.applymap(str)\n",
        "parents_all_sents[0] = parents_all_sents[0].apply(lambda x: x + ' ')\n",
        "parents_all_sents['grp'] = parents_all_sents.index // 2\n",
        "parents_all_sents = parents_all_sents.groupby('grp').sum()\n",
        "parents_all_sents[1] = 'edgeworth'\n",
        "\n",
        "stories_all_sents = stories_all_sents.applymap(str)\n",
        "stories_all_sents[0] = stories_all_sents[0].apply(lambda x: x + ' ')\n",
        "stories_all_sents['grp'] = stories_all_sents.index // 2\n",
        "stories_all_sents = stories_all_sents.groupby('grp').sum()\n",
        "stories_all_sents[1] = 'bryant'\n",
        "\n",
        "sentences = pd.concat(\n",
        "    [brown_all_sents,\n",
        "    parents_all_sents,\n",
        "    stories_all_sents])\n",
        "\n",
        "print(sentences.head())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                     0           1\n",
            "grp                                                               \n",
            "0                          I. The Absence of Mr Glass   chesterton\n",
            "1    THE consulting-rooms of Dr Orion Hood, the emi...  chesterton\n",
            "2    It must not be supposed that Dr Hood's apartme...  chesterton\n",
            "3    Luxury was there: there stood upon a special t...  chesterton\n",
            "4    Poetry was there: the left-hand corner of the ...  chesterton\n",
            "CPU times: user 714 ms, sys: 8.18 ms, total: 722 ms\n",
            "Wall time: 720 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0B84nn13G9VI",
        "colab_type": "text"
      },
      "source": [
        "Texts from 3 author were acquired from the gutenberg corpora and stored into a dataframe as sentences.\n",
        "The texts were organized into sentences to preserve the contextual information of individual tokens.\n",
        "Sentences were stored as pairs to allow for more information to be stored in each record.\n",
        "Each sentence pair was labeled with the corresponding author's name.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQebhYwt4YUW",
        "colab_type": "text"
      },
      "source": [
        "## Preparing The Data For Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KWYIZKP5lXJ",
        "colab_type": "code",
        "outputId": "d94e3440-44dc-4717-e7a8-3bc777515c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Vectorizing Text Data Using Bag Of Words\n",
        "\n",
        "porter_stemmer = PorterStemmer()\n",
        "\n",
        "def stemming_tokenizer(str_input):\n",
        "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
        "    words = [porter_stemmer.stem(word) for word in words]\n",
        "    return words\n",
        "\n",
        "count_vectorizer = CountVectorizer(stop_words='english', tokenizer=stemming_tokenizer, max_features=1000)\n",
        "X = count_vectorizer.fit_transform(sentences[0])\n",
        "df_bow = pd.DataFrame(X.toarray(), columns=count_vectorizer.get_feature_names())\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.35 s, sys: 2.75 ms, total: 1.36 s\n",
            "Wall time: 1.36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJ7EsTBK7FI0",
        "colab_type": "code",
        "outputId": "c6056c58-3d94-4203-9ef5-5fb8e5dd83ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Vectorizing Text Data Using TfIdf\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, max_features=1000, use_idf=True)\n",
        "X = tfidf_vectorizer.fit_transform(sentences[0])\n",
        "df_tfidf = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.36 s, sys: 3.25 ms, total: 1.36 s\n",
            "Wall time: 1.36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2t2Cv-X9I4qE",
        "colab_type": "text"
      },
      "source": [
        "The sentences were tokenized using bag of words and TF-IDF prior to modeling, creating two sets of tokens. Different Modeling techniques were used on each of the tokens and the results were compared.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQpABIKe442V",
        "colab_type": "text"
      },
      "source": [
        "## Modeling the Data using Bag of Words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67Lfjont-9Sc",
        "colab_type": "code",
        "outputId": "b3e31f2a-ddfe-4586-ee4c-8ae952a0aee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Establish variables based on original features to be used for modeling\n",
        "\n",
        "x = df_bow\n",
        "y = sentences[1]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.9 ms, sys: 992 µs, total: 13.8 ms\n",
            "Wall time: 13.4 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EQpu0NA49rc",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQWvrpjrvR5Q",
        "colab_type": "code",
        "outputId": "57a5fb9e-6885-4968-fe30-2532d10b7843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "bnb = BernoulliNB().fit(x_train, y_train)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.2 ms, sys: 5.92 ms, total: 45.2 ms\n",
            "Wall time: 39 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0xeQMPMvuUs",
        "colab_type": "code",
        "outputId": "02a6b024-1613-4850-fe89-25c7b5ce18ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(bnb.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(bnb, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, bnb.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, bnb.predict(x_test)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.8637532133676092\n",
            "\n",
            "cross validation:\n",
            "[0.74683544 0.71794872 0.75641026 0.72727273 0.81818182]\n",
            "\n",
            "confusion matrix:\n",
            "[[128  10   8]\n",
            " [  8 119   3]\n",
            " [ 11  13  89]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.87      0.88      0.87       146\n",
            "  chesterton       0.84      0.92      0.88       130\n",
            "   edgeworth       0.89      0.79      0.84       113\n",
            "\n",
            "    accuracy                           0.86       389\n",
            "   macro avg       0.87      0.86      0.86       389\n",
            "weighted avg       0.87      0.86      0.86       389\n",
            "\n",
            "CPU times: user 159 ms, sys: 83.1 ms, total: 242 ms\n",
            "Wall time: 135 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZHmMUv25DNs",
        "colab_type": "text"
      },
      "source": [
        "### K Nearest Neighbors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPMx3UsQAr_m",
        "colab_type": "code",
        "outputId": "e4c0a25d-ab88-43c5-de9b-5ef5475c00ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=10).fit(x_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 90.5 ms, sys: 50.1 ms, total: 141 ms\n",
            "Wall time: 81.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW3nC-8aAsjm",
        "colab_type": "code",
        "outputId": "49f0c313-b476-4514-a451-1375bddc1d56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(knn.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(knn, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, knn.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, knn.predict(x_test)))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.5372750642673522\n",
            "\n",
            "cross validation:\n",
            "[0.43037975 0.5        0.48717949 0.44155844 0.37662338]\n",
            "\n",
            "confusion matrix:\n",
            "[[103  13  30]\n",
            " [ 44  54  32]\n",
            " [ 44  17  52]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.54      0.71      0.61       146\n",
            "  chesterton       0.64      0.42      0.50       130\n",
            "   edgeworth       0.46      0.46      0.46       113\n",
            "\n",
            "    accuracy                           0.54       389\n",
            "   macro avg       0.55      0.53      0.52       389\n",
            "weighted avg       0.55      0.54      0.53       389\n",
            "\n",
            "CPU times: user 5.06 s, sys: 9.11 ms, total: 5.06 s\n",
            "Wall time: 5.07 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7HJvipV5NTi",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEOkmAzU_khj",
        "colab_type": "code",
        "outputId": "bfee2cd8-a3e9-4836-efe0-188ea7c6cd51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "decision_tree = tree.DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_features=6,\n",
        "    max_depth=25,\n",
        "    ).fit(x_train, y_train)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 18 ms, sys: 756 µs, total: 18.8 ms\n",
            "Wall time: 19.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsrxgDNPAVPX",
        "colab_type": "code",
        "outputId": "5a937a10-1956-4e95-a5f6-fec7c9c71cec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(decision_tree.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(decision_tree, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, decision_tree.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, decision_tree.predict(x_test)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.4781491002570694\n",
            "\n",
            "cross validation:\n",
            "[0.40506329 0.43589744 0.38461538 0.48051948 0.41558442]\n",
            "\n",
            "confusion matrix:\n",
            "[[136   3   7]\n",
            " [ 89  37   4]\n",
            " [ 94   6  13]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.43      0.93      0.58       146\n",
            "  chesterton       0.80      0.28      0.42       130\n",
            "   edgeworth       0.54      0.12      0.19       113\n",
            "\n",
            "    accuracy                           0.48       389\n",
            "   macro avg       0.59      0.44      0.40       389\n",
            "weighted avg       0.59      0.48      0.42       389\n",
            "\n",
            "CPU times: user 63.7 ms, sys: 3.01 ms, total: 66.7 ms\n",
            "Wall time: 67.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLB5zsy5Tp3",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxfJm18MATHC",
        "colab_type": "code",
        "outputId": "281ac703-7254-4272-9801-a8aceac8fef4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Fit and Train Model\n",
        "\n",
        "rfc = ensemble.RandomForestClassifier(\n",
        "    criterion='entropy',\n",
        "    max_features=15,\n",
        "    max_depth=100,\n",
        "    ).fit(x_train, y_train)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 91.2 ms, sys: 1 ms, total: 92.2 ms\n",
            "Wall time: 93.7 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVDgEGUeAk6u",
        "colab_type": "code",
        "outputId": "33017885-df73-4426-fc92-a8cf9d212650",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(rfc.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(rfc, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, rfc.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, rfc.predict(x_test)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.7609254498714653\n",
            "\n",
            "cross validation:\n",
            "[0.58227848 0.58974359 0.64102564 0.67532468 0.66233766]\n",
            "\n",
            "confusion matrix:\n",
            "[[125   8  13]\n",
            " [ 26  96   8]\n",
            " [ 28  10  75]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.70      0.86      0.77       146\n",
            "  chesterton       0.84      0.74      0.79       130\n",
            "   edgeworth       0.78      0.66      0.72       113\n",
            "\n",
            "    accuracy                           0.76       389\n",
            "   macro avg       0.77      0.75      0.76       389\n",
            "weighted avg       0.77      0.76      0.76       389\n",
            "\n",
            "CPU times: user 193 ms, sys: 5.08 ms, total: 198 ms\n",
            "Wall time: 197 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwXwe8uf5Waj",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyqVnwiYAmJA",
        "colab_type": "code",
        "outputId": "b38831d1-5a53-423e-f785-ade5127f0249",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "lr = LogisticRegression(fit_intercept=False).fit(x_train, y_train)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.2 ms, sys: 1.96 ms, total: 42.2 ms\n",
            "Wall time: 43.2 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XYGO5_KAnLe",
        "colab_type": "code",
        "outputId": "bd7dacac-1960-4e79-c581-bd3432c3d50c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(lr.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(lr, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, lr.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, lr.predict(x_test)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.8508997429305912\n",
            "\n",
            "cross validation:\n",
            "[0.7721519  0.73076923 0.70512821 0.72727273 0.75324675]\n",
            "\n",
            "confusion matrix:\n",
            "[[131   6   9]\n",
            " [ 12 113   5]\n",
            " [ 16  10  87]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.82      0.90      0.86       146\n",
            "  chesterton       0.88      0.87      0.87       130\n",
            "   edgeworth       0.86      0.77      0.81       113\n",
            "\n",
            "    accuracy                           0.85       389\n",
            "   macro avg       0.85      0.85      0.85       389\n",
            "weighted avg       0.85      0.85      0.85       389\n",
            "\n",
            "CPU times: user 132 ms, sys: 84.2 ms, total: 216 ms\n",
            "Wall time: 122 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmltsXeKWo0j",
        "colab_type": "text"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQaG0IGLW02Y",
        "colab_type": "code",
        "outputId": "ba8f8cf9-ded3-4b6e-cf83-309c12083ff1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,)).fit(x_train, y_train)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 19.8 s, sys: 9.47 s, total: 29.3 s\n",
            "Wall time: 14.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OigP0dBuW8c7",
        "colab_type": "code",
        "outputId": "68ea2a4f-a961-4112-e11d-2103b5314461",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(mlp.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(mlp, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, mlp.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, mlp.predict(x_test)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.8251928020565553\n",
            "\n",
            "cross validation:\n",
            "[0.74683544 0.76923077 0.71794872 0.72727273 0.79220779]\n",
            "\n",
            "confusion matrix:\n",
            "[[123   8  15]\n",
            " [  9 113   8]\n",
            " [ 17  11  85]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.83      0.84      0.83       146\n",
            "  chesterton       0.86      0.87      0.86       130\n",
            "   edgeworth       0.79      0.75      0.77       113\n",
            "\n",
            "    accuracy                           0.83       389\n",
            "   macro avg       0.82      0.82      0.82       389\n",
            "weighted avg       0.82      0.83      0.82       389\n",
            "\n",
            "CPU times: user 24 s, sys: 10.9 s, total: 34.9 s\n",
            "Wall time: 17.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpTQUQn75gpx",
        "colab_type": "text"
      },
      "source": [
        "## Modeling the Data using TF-IDF\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHJKuiLv_Fvl",
        "colab_type": "code",
        "outputId": "7034bd33-2d25-4daf-eba4-d4f0e81370d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Establish variables based on original features to be used for modeling\n",
        "\n",
        "x = df_tfidf\n",
        "y = sentences[1]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.3 ms, sys: 6.45 ms, total: 21.8 ms\n",
            "Wall time: 16.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpqu5ila5j8J",
        "colab_type": "text"
      },
      "source": [
        "### Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YWt2YrHAuHX",
        "colab_type": "code",
        "outputId": "d71517d2-5399-4eec-fa28-2fac35d832e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "bnb = BernoulliNB().fit(x_train, y_train)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.3 ms, sys: 21.8 ms, total: 61.1 ms\n",
            "Wall time: 35.3 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ1i9oJFAukV",
        "colab_type": "code",
        "outputId": "59211efe-748f-49ef-d713-5d1f42387ba7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(bnb.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(bnb, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, bnb.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, bnb.predict(x_test)))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.8637532133676092\n",
            "\n",
            "cross validation:\n",
            "[0.74683544 0.71794872 0.75641026 0.72727273 0.81818182]\n",
            "\n",
            "confusion matrix:\n",
            "[[128  10   8]\n",
            " [  8 119   3]\n",
            " [ 11  13  89]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.87      0.88      0.87       146\n",
            "  chesterton       0.84      0.92      0.88       130\n",
            "   edgeworth       0.89      0.79      0.84       113\n",
            "\n",
            "    accuracy                           0.86       389\n",
            "   macro avg       0.87      0.86      0.86       389\n",
            "weighted avg       0.87      0.86      0.86       389\n",
            "\n",
            "CPU times: user 143 ms, sys: 86 ms, total: 229 ms\n",
            "Wall time: 128 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ou32_DM5mXa",
        "colab_type": "text"
      },
      "source": [
        "### K Nearest Neighbors "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmcgUgvvAu-y",
        "colab_type": "code",
        "outputId": "0d3c9791-d75e-4070-dd48-554c7b327d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "knn = neighbors.KNeighborsClassifier(n_neighbors=10).fit(x_train, y_train)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 94.4 ms, sys: 52.6 ms, total: 147 ms\n",
            "Wall time: 81.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITX9Ec7UAvWF",
        "colab_type": "code",
        "outputId": "8483c5ee-e659-46e7-b74b-b29bd6423cd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(knn.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(knn, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, knn.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, knn.predict(x_test)))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.442159383033419\n",
            "\n",
            "cross validation:\n",
            "[0.73417722 0.70512821 0.55128205 0.37662338 0.64935065]\n",
            "\n",
            "confusion matrix:\n",
            "[[40 33 73]\n",
            " [ 1 57 72]\n",
            " [ 1 37 75]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.95      0.27      0.43       146\n",
            "  chesterton       0.45      0.44      0.44       130\n",
            "   edgeworth       0.34      0.66      0.45       113\n",
            "\n",
            "    accuracy                           0.44       389\n",
            "   macro avg       0.58      0.46      0.44       389\n",
            "weighted avg       0.61      0.44      0.44       389\n",
            "\n",
            "CPU times: user 4.98 s, sys: 6.94 ms, total: 4.99 s\n",
            "Wall time: 4.99 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEmtaXJr5o9O",
        "colab_type": "text"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbm4U84VAwEV",
        "colab_type": "code",
        "outputId": "eec3a806-ea5f-41cf-f546-0c70b66fd9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "decision_tree = tree.DecisionTreeClassifier(\n",
        "    criterion='entropy',\n",
        "    max_features=6,\n",
        "    max_depth=25,\n",
        "    ).fit(x_train, y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 17.6 ms, sys: 451 µs, total: 18 ms\n",
            "Wall time: 20.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_D35K3HAwc2",
        "colab_type": "code",
        "outputId": "c73b8e77-5b7a-485c-8e11-065d8492156c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(decision_tree.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(decision_tree, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, decision_tree.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, decision_tree.predict(x_test)))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.442159383033419\n",
            "\n",
            "cross validation:\n",
            "[0.39240506 0.44871795 0.41025641 0.54545455 0.4025974 ]\n",
            "\n",
            "confusion matrix:\n",
            "[[132   4  10]\n",
            " [107  21   2]\n",
            " [ 94   0  19]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.40      0.90      0.55       146\n",
            "  chesterton       0.84      0.16      0.27       130\n",
            "   edgeworth       0.61      0.17      0.26       113\n",
            "\n",
            "    accuracy                           0.44       389\n",
            "   macro avg       0.62      0.41      0.36       389\n",
            "weighted avg       0.61      0.44      0.37       389\n",
            "\n",
            "CPU times: user 63 ms, sys: 2.52 ms, total: 65.5 ms\n",
            "Wall time: 68.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUza84dL5nUX",
        "colab_type": "text"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmKGVdODAw9F",
        "colab_type": "code",
        "outputId": "996841a4-5d95-4b3e-db48-1269febf89d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Fit and Train Model\n",
        "\n",
        "rfc = ensemble.RandomForestClassifier(\n",
        "    criterion='entropy',\n",
        "    max_features=15,\n",
        "    max_depth=100,\n",
        "    ).fit(x_train, y_train)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 102 ms, sys: 1.04 ms, total: 103 ms\n",
            "Wall time: 103 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLDMuZyEAxSt",
        "colab_type": "code",
        "outputId": "c69b8f7d-ecda-429f-95cb-93160b5a51d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(rfc.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(rfc, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, rfc.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, rfc.predict(x_test)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.8097686375321337\n",
            "\n",
            "cross validation:\n",
            "[0.60759494 0.57692308 0.62820513 0.54545455 0.71428571]\n",
            "\n",
            "confusion matrix:\n",
            "[[131   7   8]\n",
            " [ 20 106   4]\n",
            " [ 22  13  78]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.76      0.90      0.82       146\n",
            "  chesterton       0.84      0.82      0.83       130\n",
            "   edgeworth       0.87      0.69      0.77       113\n",
            "\n",
            "    accuracy                           0.81       389\n",
            "   macro avg       0.82      0.80      0.81       389\n",
            "weighted avg       0.82      0.81      0.81       389\n",
            "\n",
            "CPU times: user 181 ms, sys: 2.38 ms, total: 184 ms\n",
            "Wall time: 181 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90E5EnHo5u9Z",
        "colab_type": "text"
      },
      "source": [
        "### Logistic Regression "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW5__RpxAx4e",
        "colab_type": "code",
        "outputId": "24fc2ebb-1b06-4ec7-ad7c-e3724d6120a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "lr = LogisticRegression(fit_intercept=False).fit(x_train, y_train)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.7 ms, sys: 0 ns, total: 25.7 ms\n",
            "Wall time: 24.9 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uYVvsLLAyQU",
        "colab_type": "code",
        "outputId": "31e4e595-7704-4fd2-cc8b-b2ec1e87c382",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(lr.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(lr, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, lr.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, lr.predict(x_test)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.8586118251928021\n",
            "\n",
            "cross validation:\n",
            "[0.75949367 0.73076923 0.73076923 0.68831169 0.77922078]\n",
            "\n",
            "confusion matrix:\n",
            "[[132   6   8]\n",
            " [ 12 113   5]\n",
            " [ 17   7  89]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.82      0.90      0.86       146\n",
            "  chesterton       0.90      0.87      0.88       130\n",
            "   edgeworth       0.87      0.79      0.83       113\n",
            "\n",
            "    accuracy                           0.86       389\n",
            "   macro avg       0.86      0.85      0.86       389\n",
            "weighted avg       0.86      0.86      0.86       389\n",
            "\n",
            "CPU times: user 112 ms, sys: 56.4 ms, total: 169 ms\n",
            "Wall time: 106 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCd8Xk0NXlTq",
        "colab_type": "text"
      },
      "source": [
        "### Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwGvuDctXjQg",
        "colab_type": "code",
        "outputId": "7faa7c87-d46f-4300-9fc3-f0ca5417e5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100,)).fit(x_train, y_train)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 20.2 s, sys: 8.18 s, total: 28.4 s\n",
            "Wall time: 14.3 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKejCCwmXqLn",
        "colab_type": "code",
        "outputId": "3820c2ff-3ba3-4ed0-de4a-5a6c712f2d1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(mlp.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(mlp, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, mlp.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, mlp.predict(x_test)))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.8251928020565553\n",
            "\n",
            "cross validation:\n",
            "[0.78481013 0.80769231 0.73076923 0.75324675 0.83116883]\n",
            "\n",
            "confusion matrix:\n",
            "[[125   6  15]\n",
            " [  9 109  12]\n",
            " [ 17   9  87]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.83      0.86      0.84       146\n",
            "  chesterton       0.88      0.84      0.86       130\n",
            "   edgeworth       0.76      0.77      0.77       113\n",
            "\n",
            "    accuracy                           0.83       389\n",
            "   macro avg       0.82      0.82      0.82       389\n",
            "weighted avg       0.83      0.83      0.83       389\n",
            "\n",
            "CPU times: user 21.9 s, sys: 9.19 s, total: 31.1 s\n",
            "Wall time: 15.7 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcAlqsyt54sw",
        "colab_type": "text"
      },
      "source": [
        "## Revising TF-IDF Based Logistic Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOv0afgHAcqh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "132a3b60-817c-4ca4-bc9b-0f411e289ada"
      },
      "source": [
        "%%time\n",
        "\n",
        "## Process Text into Groups of Four\n",
        "\n",
        "brown_all_sents['grp2'] = brown_all_sents.index //2\n",
        "brown_all_sents = brown_all_sents.groupby('grp2').sum()\n",
        "brown_all_sents[1] = 'chesterton'\n",
        "\n",
        "parents_all_sents['grp2'] = parents_all_sents.index // 2\n",
        "parents_all_sents = parents_all_sents.groupby('grp2').sum()\n",
        "parents_all_sents[1] = 'edgeworth'\n",
        "\n",
        "stories_all_sents['grp2'] = stories_all_sents.index // 2\n",
        "stories_all_sents = stories_all_sents.groupby('grp2').sum()\n",
        "stories_all_sents[1] = 'bryant'\n",
        "\n",
        "sentences = pd.concat(\n",
        "    [brown_all_sents,\n",
        "    parents_all_sents,\n",
        "    stories_all_sents])\n",
        "\n",
        "print(sentences.head())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                      0           1\n",
            "grp2                                                               \n",
            "0     I. The Absence of Mr Glass THE consulting-room...  chesterton\n",
            "1     It must not be supposed that Dr Hood's apartme...  chesterton\n",
            "2     Poetry was there: the left-hand corner of the ...  chesterton\n",
            "3     And if this strict scientific intangibility st...  chesterton\n",
            "4     Fate, being in a funny mood, pushed the door o...  chesterton\n",
            "CPU times: user 344 ms, sys: 66.7 ms, total: 411 ms\n",
            "Wall time: 329 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCZRNy6AB9NV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "29395abc-9c66-4e23-ee80-301eb0200933"
      },
      "source": [
        "%%time\n",
        "\n",
        "## Vectorizing Text Data Using TfIdf\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, max_features=1000, use_idf=True)\n",
        "X = tfidf_vectorizer.fit_transform(sentences[0])\n",
        "df_tfidf = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.35 s, sys: 2.08 ms, total: 1.35 s\n",
            "Wall time: 1.36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7OgtsKnCP7e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d07b6eb7-5d88-45d1-a214-0ab2894562db"
      },
      "source": [
        "%%time\n",
        "\n",
        "## Establish variables based on original features to be used for modeling\n",
        "\n",
        "x = df_tfidf\n",
        "y = sentences[1]\n",
        "\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=20)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.02 ms, sys: 1.03 ms, total: 9.05 ms\n",
            "Wall time: 8.06 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InV9giFlCn_9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0cfcac62-68fa-404d-b5ed-0ee90a2ad860"
      },
      "source": [
        "%%time\n",
        "\n",
        "## train and fit model\n",
        "\n",
        "lr = LogisticRegression(fit_intercept=False).fit(x_train, y_train)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 15.7 ms, sys: 771 µs, total: 16.5 ms\n",
            "Wall time: 24.5 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fkY2VeeCphU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "a7df0f2f-033a-41b9-f0e6-d2aa40f4ab0c"
      },
      "source": [
        "%%time\n",
        "\n",
        "## Model Evaluation\n",
        "\n",
        "print(\"accuracy score:\\n\" + str(lr.score(x_test, y_test))+'\\n')\n",
        "\n",
        "print(\"cross validation:\\n\" + str(cross_val_score(lr, x_test, y_test, cv=5))+'\\n')\n",
        "\n",
        "print(\"confusion matrix:\\n\" + str(confusion_matrix(y_test, lr.predict(x_test)))+'\\n')\n",
        "\n",
        "print(classification_report(y_test, lr.predict(x_test)))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy score:\n",
            "0.9487179487179487\n",
            "\n",
            "cross validation:\n",
            "[0.825      0.82051282 0.82051282 0.87179487 0.84210526]\n",
            "\n",
            "confusion matrix:\n",
            "[[63  1  1]\n",
            " [ 3 56  0]\n",
            " [ 3  2 66]]\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      bryant       0.91      0.97      0.94        65\n",
            "  chesterton       0.95      0.95      0.95        59\n",
            "   edgeworth       0.99      0.93      0.96        71\n",
            "\n",
            "    accuracy                           0.95       195\n",
            "   macro avg       0.95      0.95      0.95       195\n",
            "weighted avg       0.95      0.95      0.95       195\n",
            "\n",
            "CPU times: user 76.6 ms, sys: 55.3 ms, total: 132 ms\n",
            "Wall time: 79.6 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2MXEmjXLSxz",
        "colab_type": "text"
      },
      "source": [
        "The number of sentences per record was increased to four to increase the accuracy of the best performing model type in this study; the Logistic Regression model with TF-IDF tokens. Performance increased by over 10 percent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcCVg1yE57C_",
        "colab_type": "text"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyoS8AY0Lg0D",
        "colab_type": "text"
      },
      "source": [
        "By comparing different model types and types of NLP methods, it was ascertained that TF-IDF paired with Logistic regression yielded the best results.\n",
        "TF-IDF generally had better performance than bag of words.\n",
        "This study has given added insight into NLP practices that yield higher accuracy and give more information about analyzed texts.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0HkGW7mNpFX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}