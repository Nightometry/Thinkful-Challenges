{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis: Classifying Amazon Healthcare Product Reviews \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.58 s, sys: 476 ms, total: 2.05 s\n",
      "Wall time: 1.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import math\n",
    "import re\n",
    "import warnings\n",
    "\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib.mlab import PCA as mlabPCA\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import neighbors\n",
    "from sklearn.utils import resample\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import ensemble\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"sklearn\"  \n",
    "    )\n",
    "\n",
    "# Set Plot Style\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.extmath import randomized_svd\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.56 s, sys: 1.08 s, total: 5.64 s\n",
      "Wall time: 5.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Import Files\n",
    "\n",
    "df = pd.read_json('Health_and_Personal_Care_5.json', lines=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## View Data for Cleaning\n",
    "\n",
    "#df.head(7)\n",
    "#df.dtypes\n",
    "#df.describe()\n",
    "#df.isnull().sum(axis = 0)\n",
    "#len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 196 ms, sys: 8.49 ms, total: 204 ms\n",
      "Wall time: 203 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Drop Unnecessary Columns\n",
    "\n",
    "df=df.drop('reviewerName', axis=1)\n",
    "df=df.drop('reviewTime', axis=1)\n",
    "\n",
    "## Separate Original Dataset into Separate DataFrames for Different Cleaning Implementations\n",
    "\n",
    "df_without_text = df.drop(['reviewText', 'summary', 'reviewerID', 'asin'], axis=1)\n",
    "df_review_text = df.reviewText\n",
    "df_review_summary = df.summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.16 s, sys: 149 ms, total: 3.31 s\n",
      "Wall time: 3.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Converting Helpfulness Rating to float\n",
    "\n",
    "df_without_text.helpful = df_without_text.helpful.apply(lambda x: str(x).replace('[','').replace(', ','/').replace(']',''))\n",
    "\n",
    "df_without_text.helpful = df_without_text.helpful.replace('0/0','0')\n",
    "\n",
    "df_without_text.helpful = df_without_text.helpful.apply(eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min, sys: 29.9 s, total: 12min 30s\n",
      "Wall time: 12min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "## Vectorizing Text Data\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "def stemming_tokenizer(str_input):\n",
    "    words = re.sub(r\"[^A-Za-z0-9\\-]\", \" \", str_input).lower().split()\n",
    "    words = [porter_stemmer.stem(word) for word in words]\n",
    "    return words\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=True)\n",
    "X = tfidf_vectorizer.fit_transform(df_review_text)\n",
    "df_review_text_vectorized = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english', tokenizer=stemming_tokenizer, use_idf=True)\n",
    "X = tfidf_vectorizer.fit_transform(df_review_summary)\n",
    "df_review_summary_vectorized = pd.DataFrame(X.toarray(), columns=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np_review_text_vectorized = scipy.sparse.csr_matrix(df_review_text_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Dimension reduction\n",
    "\n",
    "#svd= randomized_svd(df_review_text_vectorized, n_components=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimension reduction\n",
    "\n",
    "svd= TruncatedSVD(200)\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "df_review_summary_components = lsa.fit_transform(df_review_text_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_review_text_vectorized.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(eval('0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(1329523200).timestamp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Plan\n",
    "\n",
    "create 3 separate dataframes one with just the review text, one with everything else, one with the summary\n",
    "\n",
    "Clean Other variables: <br>\n",
    "Turn helpfulness review into a fraction <br>\n",
    "Convert overall to positive or negative (4 or 5 is positive) <br>\n",
    "\n",
    "convert unix review time (maybe just for analysis)\n",
    "\n",
    "Vectorize review text <br>\n",
    "\n",
    "Vectorize summary text\n",
    "\n",
    "Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "#df.describe()\n",
    "#df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes\n",
    "#df.describe()\n",
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration review id: if review id are few and far enough apart it can be dropped from the model (compare value counts to len df)/ drop reviewer name regardless\n",
    "read reviews as part of the data analysis (query)\n",
    "Summary tokens were intentionally not unionized with review tokens so that the model could pick up on the differences\n",
    "debate whether to include product name in actual model\n",
    "consider additional feature engineering to account for helpfulness rating\n",
    "debate keeping review id and product id\n",
    "\n",
    "Include examples of types of products in the data analysis\n",
    "mention how overall was made/  how data was labeled"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
